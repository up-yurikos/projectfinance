import streamlit as st
import pandas as pd
import zipfile, io, re, tempfile, gdown, calendar
from datetime import date, datetime
from dateutil.relativedelta import relativedelta
from st_aggrid import AgGrid, GridOptionsBuilder
from st_aggrid.shared import GridUpdateMode

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# å›ºå®šãƒãƒƒãƒ”ãƒ³ã‚° : RecordID (Båˆ—) âœ DealID (Cåˆ—)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ID_MAP_FIXED = {
    'AKE202210_KEIEI_U': '9775650935',
    'AMA202211_SYSTEM_P': '13111634538',
    'AMA202304_2BREPO_P': '13111594792',
    'AMA202304_ECREPO_P': '13111634452',
    'AMA202304_ECSYST_P': '13111594849',
    'AMA202305_BILLIN_P': '13334264959',
    'AMA202306_SCMPMO_P': '13826848558',
    'AMA202307_ELSIGN_P': '13965251380',
    'AMA202307_MGTADV_U': '13906057056',
    'ARA202308_JIGYOU_P': '12746802825',
    'BRI202309_OTHERS_P': '12850387035',
    'BRI202310_PMOSUP_P': '16033621034',
    'CLE202304_CDMOTR_U': '13523440943',
    'DAI202309_OTHERS_P': '15098798720',
    'DEK202307_OTHERS_P': '12911619969',
    'DEK202308_OTHERS_U': '13964560773',
    'DEK202312_FASMAA_U': '16351470488',
    'DEK202312_OTHERS_U': '16037489190',
    'DEN202210_JIGYOU_P': '10172816231',
    'DEN202302_JIGYOU_U': '12030335245',
    'DEN202309_JIGYOU_P': '13909275047',
    'DEN202309_OTHERS_P': '14767850896',
    'ELN202303_VISASQ_U': '12602652171',
    'FAN202302_HOKUBE_U': '11770846345',
    'FUJ202302_JIGYOU_U': '12158729512',
    'FUT202308_DXSTRA_P': '14148089088',
    'HIR202211_ESSYST_P': '10362965791',
    'HIR202302_ESCONS_U': '12073670611',
    'HIR202302_JIGYOU_U': '12073670418',
    'HIR202302_JPSGAN_U': '12073670158',
    'HIR202303_JIGYOU_U': '12170849132',
    'HIR202304_JIGYOU_U': '12223160017',
    'HIR202305_JIGYOU_U': '12363647079',
    'HIR202306_JIGYOU_U': '12515803893',
    'HIR202307_JIGYOU_U': '13111138855',
    'HIR202308_OTHERS_U': '13739060018',
    'HIR202309_JIGYOU_U': '13964605132',
    'HIT202302_JIGYOU_U': '11934460122',
    'HIT202304_DXCONS_U': '12394681781',
    'HIT202305_OTHERS_P': '12394681487',
    'HIT202306_OTHERS_P': '12561539312',
    'HIT202307_OTHERS_P': '13111138884',
    'HIT202308_OTHERS_P': '13737542047',
    'HIT202309_OTHERS_P': '14767850830',
    'INM202307_DXCONS_P': '12747279127',
    'INM202309_DXCONS_P': '14767043959',
    'JDC202308_JIGYOU_U': '13739310719',
    'JDC202309_OTHERS_U': '14671654128',
    'KAK202303_DXMKTG_P': '12561292342',
    'KAK202304_SUSTAI_P': '12223160034',
    'KAK202306_OTHERS_P': '12665061861',
    'KAK202307_OTHERS_P': '12910901831',
    'KAK202308_OTHERS_P': '13739059963',
    'KAK202309_OTHERS_P': '14671654171',
    'KOK202306_OTHERS_P': '12910901839',
    'KOK202307_OTHERS_P': '12910901845',
    'KOK202308_OTHERS_P': '13737542079',
    'KOK202309_OTHERS_P': '14671654191',
    'KYO202210_MDTYPE_P': '10172816310',
    'KYO202303_OTHERS_P': '12561292366',
    'KYO202304_OTHERS_P': '12257979771',
    'LIF202308_OTHERS_P': '14148089119',
    'LIF202309_OTHERS_P': '15100050932',
    'MIK202308_OTHERS_P': '13737542093',
    'MON202210_TAXSPA_P': '10455428996',
    'MON202211_TAXSPA_P': '10455429076',
    'MON202301_TAXSPA_P': '11770846395',
    'MON202302_TAXSPA_P': '12158729536',
    'MON202303_OTHERS_P': '12456413016',
    'MON202304_OTHERS_P': '12223160047',
    'MON202306_TAXSPA_P': '12561539221',
    'MON202307_OTHERS_P': '12911619960',
    'MON202308_OTHERS_P': '13737542107',
    'MON202309_OTHERS_P': '15100050944',
    'NIT202210_OPMKTG_P': '10172590823',
    'NRI202210_DXCONS_P': '10172816325',
    'NSS202302_DXSTRA_P': '11770846424',
    'NSS202306_OTHERS_P': '12561539273',
    'NSS202307_OTHERS_P': '12911220631',
    'NSS202308_OTHERS_P': '13739060041',
    'NSS202309_OTHERS_P': '13964605170',
    'OKI202307_OTHERS_P': '12911619977',
    'OKI202308_OTHERS_P': '13739060051',
    'OKI202309_OTHERS_P': '14671654213',
    'RIC202309_OTHERS_P': '14767171462',
    'RYO202308_DXSTRA_P': '14148089146',
    'SHP202210_DXSTRA_P': '10455429113',
    'SHP202307_OTHERS_P': '12910901871',
    'SHP202308_OTHERS_P': '13737542123',
    'SHP202309_OTHERS_P': '14767850911',
    'SMB202210_JIGYOU_P': '10172816344',
    'SMB202302_JIGYOU_U': '11770846443',
    'SMB202304_JIGYOU_P': '12257979795',
    'SMB202306_JIGYOU_P': '12602652214',
    'SMB202307_JIGYOU_P': '12910901890',
    'SMB202308_JIGYOU_P': '13737542137',
    'SMB202309_JIGYOU_P': '14768031259',
    'SMT202210_SYSMIG_P': '10172816352',
    'SMT202210_SYSTUN_P': '10172816371',
    'SMT202212_JIGYOU_P': '10363337802',
    'SMT202303_JIGYOU_P': '12561292418',
    'SMT202304_JIGYOU_P': '12257979805',
    'SMT202305_OTHERS_P': '12394681563',
    'SMT202306_OTHERS_P': '12561539286',
    'SMT202307_OTHERS_P': '12911220662',
    'SMT202308_OTHERS_P': '13739060064',
    'SMT202309_OTHERS_P': '13964605187',
    'SNS202309_OTHERS_P': '13964605191',
    'TAX202210_OTHERS_P': '10455429145',
    'TAX202302_HOKUBE_U': '11770846459',
    'TSC202301_SYSTEM_P': '9739381018',
    'TTS202304_JIGRESEAC_P': '12783695123',
    'TTS202306_VISASQ_U': '13374247579',
    'UAC202308_OTHERS_P': '13963049397',
    'UAC202307_OTHERS_P': '13411248700',
    'YON202301_DXSTRA_P': '12456413034',
    'YON202308_OTHERS_U': '13737542160',
    'YON202309_DXSTRA_P': '14446752905',
    'YON202312_DXSTRA_P': '15481667376'
}

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ãƒšãƒ¼ã‚¸è¨­å®š
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(page_title="ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆåç›Š v7.2", layout="wide")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# å…±é€šãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def detect_col(cols, patterns):
    for p in patterns:
        hits = [c for c in cols if re.sub(r"\s+", "", str(c)).casefold() == p]
        if hits:
            return hits[0]
    return None


def normalize_id(x):
    if pd.isna(x):
        return None
    s = str(x).strip()
    return None if s == "" or s.lower() in {"nan", "none"} else s


# â”€â”€ CSV / ZIP ãƒ­ãƒ¼ãƒ€ ---------------------------------------------------------
def load_csv(uploaded):
    """â‘  CSV â‘¡ ZIP å†… CSV ã‚’ DataFrame ã§è¿”ã™"""
    if uploaded is None:
        return None

    # ZIP
    if uploaded.name.lower().endswith(".zip"):
        try:
            with zipfile.ZipFile(uploaded) as zf:
                csv_files = [n for n in zf.namelist()
                             if n.lower().endswith(".csv") and not n.endswith("/")]
                if not csv_files:
                    st.error("ZIP ã« CSV ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
                    return None
                target = csv_files[0] if len(csv_files) == 1 else \
                         st.selectbox("ZIP å†… CSV ã‚’é¸æŠã—ã¦ãã ã•ã„", csv_files)
                with zf.open(target) as fp:
                    for enc in ("utf-8-sig", "cp932", "utf-8"):
                        try:
                            txt = fp.read().decode(enc)
                            return pd.read_csv(io.StringIO(txt))
                        except Exception:
                            fp.seek(0)
        except zipfile.BadZipFile:
            st.error("ZIP ãƒ•ã‚¡ã‚¤ãƒ«ãŒå£Šã‚Œã¦ã„ã¾ã™ã€‚")
            return None

    # é€šå¸¸ CSV
    for enc in ("utf-8-sig", "cp932", "utf-8"):
        try:
            txt = uploaded.read().decode(enc)
            return pd.read_csv(io.StringIO(txt))
        except Exception:
            uploaded.seek(0)

    st.error("CSV ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚æ–‡å­—ã‚³ãƒ¼ãƒ‰ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
    return None


# â”€â”€ Google Drive å…±æœ‰ãƒªãƒ³ã‚¯ ---------------------------------------------------
def read_gdrive_csv_gdown(url: str, **kw) -> pd.DataFrame:
    """å…±æœ‰ãƒªãƒ³ã‚¯ â†’ gdown ã§ DL â†’ DataFrame"""
    with tempfile.NamedTemporaryFile(delete=False, suffix=".csv") as tmp:
        gdown.download(url=url, output=tmp.name, quiet=False, fuzzy=True)
        return pd.read_csv(tmp.name, **kw)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ã‚µã‚¤ãƒ‰ãƒãƒ¼ : ãƒ‡ãƒ¼ã‚¿å…¥åŠ›ï¼ˆExpanderï¼‰
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
with st.sidebar.expander("ğŸ“‚ ãƒ‡ãƒ¼ã‚¿ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ / é¸æŠ", expanded=True):
    # ä»•è¨³å¸³
    tab_local, tab_drive = st.tabs(["ãƒ­ãƒ¼ã‚«ãƒ« CSV / ZIP", "Google Drive å…±æœ‰ãƒªãƒ³ã‚¯"])

    with tab_local:
        uploaded_file = st.file_uploader("ä»•è¨³å¸³ (CSV / ZIP), journal", type=["csv", "zip"])

    with tab_drive:
        gdrive_url = st.text_input("å…±æœ‰ãƒªãƒ³ã‚¯ã‚’è²¼ã£ã¦ Enter",
                                   placeholder="https://drive.google.com/file/d/â€¦/view?usp=sharing")
        if gdrive_url and not gdrive_url.startswith("http"):
            st.warning("ãƒªãƒ³ã‚¯å½¢å¼ãŒæ­£ã—ãã‚ã‚Šã¾ã›ã‚“ã€‚")
            gdrive_url = ""

    st.markdown("---")

    # å–å¼•ãƒã‚¹ã‚¿ / ç¨¼åƒã‚³ã‚¹ãƒˆ
    cost_file   = st.file_uploader("ç¨¼åƒã‚³ã‚¹ãƒˆ (CSV), utilization", type="csv")
    master_file = st.file_uploader("å–å¼•ãƒã‚¹ã‚¿ (CSV), transaction", type="csv")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ãƒ•ã‚¡ã‚¤ãƒ«æœªã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ™‚ã®ã‚¬ã‚¤ãƒ€ãƒ³ã‚¹è¡¨ç¤º
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
guidance_condition = (
    (uploaded_file is None) and
    (cost_file is None) and
    (master_file is None) and
    (not gdrive_url)
)
if guidance_condition:
    st.markdown("## Read me: ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ‡ãƒ¼ã‚¿ã®å–å¾—æ–¹æ³•")
    card_style = (
        "background-color:rgba(173,230,180,0.2);"
        "padding:32px;"
        "border-radius:8px;"
        "margin-bottom:16px;"
    )
    st.markdown(
        f"""
        <div style="{card_style}">
        <h4>ä»•è¨³å¸³ï¼ˆjournalï¼‰</h4>
        <ol style="padding-left:16px; margin-top:0; margin-bottom:0;">
          <li>Freeeã«ã¦ã€Œä¼šè¨ˆå¸³ç°¿ã€ï¼ã€Œä»•è¨³å¸³ã€ã‚’é–‹ã</li>
          <li>å–å¼•æ—¥ã‚’ä»»æ„ã®æœŸé–“ã«è¨­å®š</li>
          <li>ã€Œã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒ»ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã€ï¼ã€ŒCSVãƒ»PDFã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã€ï¼ã€Œï¼ˆæ–°ï¼‰CSVã€ï¼Shift_JISï¼å‡ºåŠ›ã§ãƒ•ã‚¡ã‚¤ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰</li>
          <li>ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ <strong>"journal"</strong> ã«å¤‰æ›´</li>
        </ol>
        </div>
        """,
        unsafe_allow_html=True
    )
    st.markdown(
        f"""
        <div style="{card_style}">
        <h4>ç¨¼åƒã‚³ã‚¹ãƒˆï¼ˆutilizationï¼‰</h4>
        <ol style="padding-left:16px; margin-top:0; margin-bottom:0;">
          <li>HubSpotã‚ˆã‚Šã€ŒUPç¤¾å“¡/ã‚¢ã‚µã‚¤ãƒ³å±¥æ­´ã€ãƒ¬ãƒãƒ¼ãƒˆã‚’CSVã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ</li>
          <li>ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ <strong>"utilization"</strong> ã«å¤‰æ›´</li>
        </ol>
        </div>
        """,
        unsafe_allow_html=True
    )
    st.markdown(
        f"""
        <div style="{card_style}">
        <h4>å–å¼•ãƒã‚¹ã‚¿ï¼ˆtransactionï¼‰</h4>
        <ol style="padding-left:16px; margin-top:0; margin-bottom:0;">
          <li>HubSpotã‚ˆã‚Šã€ŒCRMã€ï¼ã€Œå–å¼•ã€ã‹ã‚‰ã™ã¹ã¦ã®å–å¼•ã‚’CSVã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ</li>
          <li>ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ <strong>"transaction"</strong> ã«å¤‰æ›´</li>
        </ol>
        </div>
        """,
        unsafe_allow_html=True
    )

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ä»•è¨³å¸³èª­è¾¼
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
df_src = None
if uploaded_file is not None:
    df_src = load_csv(uploaded_file)
elif gdrive_url:
    try:
        df_src = read_gdrive_csv_gdown(gdrive_url, encoding="cp932")
    except Exception as e:
        st.error(f"Google Drive èª­ã¿è¾¼ã¿å¤±æ•—: {e}")
if df_src is None:
    st.stop()
df_src["å–å¼•æ—¥"] = pd.to_datetime(df_src["å–å¼•æ—¥"], errors="coerce")

# ---------- RecordID â†’ DealID ç½®æ›ï¼ˆå›ºå®šãƒãƒƒãƒ”ãƒ³ã‚°ï¼‰ ----------
TARGET_COLS = ["è²¸æ–¹éƒ¨é–€", "å€Ÿæ–¹éƒ¨é–€"]
for col in TARGET_COLS:
    if col in df_src.columns:
        df_src[col] = df_src[col].map(lambda x: ID_MAP_FIXED.get(normalize_id(x), x))

# å–å¼•ãƒã‚¹ã‚¿èª­è¾¼ -----------------------------------------------------
master_map = None
if master_file:
    df_master = load_csv(master_file)
    if df_master is not None:
        df_master.columns = df_master.columns.map(str.strip)
        id_col   = detect_col(df_master.columns, ["å–å¼•id","ãƒ¬ã‚³ãƒ¼ãƒ‰id","recordid","dealid"])
        amt_col  = detect_col(df_master.columns, ["é‡‘é¡","å£²ä¸Šé‡‘é¡","è¦‹ç©é‡‘é¡","amount"])
        if id_col and amt_col:
            df_master[id_col]  = df_master[id_col].map(normalize_id)
            df_master[amt_col] = pd.to_numeric(df_master[amt_col], errors="coerce").fillna(0)
            keep = {id_col:"å–å¼•ã‚³ãƒ¼ãƒ‰", amt_col:"ãƒã‚¹ã‚¿ãƒ¼é‡‘é¡"}
            for src, dst in [
                (["å–å¼•å…ˆ","ä¼šç¤¾å","customer","client"],"ãƒã‚¹ã‚¿ãƒ¼å–å¼•å…ˆ"),
                (["å–å¼•å","æ¡ˆä»¶å","dealname","title"],"å–å¼•å"),
                (["å–å¼•æ‹…å½“è€…","æ‹…å½“è€…","owner","sales"],"å–å¼•æ‹…å½“è€…"),
                (["industry","æ¥­ç•Œ"],"Industry"),
                (["industryè©³ç´°","industrydetail","æ¥­ç•Œè©³ç´°"],"Industryè©³ç´°"),
                (["ææ¡ˆå•†æ","proposal","product"],"ææ¡ˆå•†æ")
            ]:
                c = detect_col(df_master.columns, src)
                if c: keep[c] = dst
            master_map = (df_master[list(keep)]
                          .dropna(subset=[id_col])
                          .rename(columns=keep)
                          .drop_duplicates(subset=["å–å¼•ã‚³ãƒ¼ãƒ‰"]))

# ç¨¼åƒã‚³ã‚¹ãƒˆèª­è¾¼ -----------------------------------------------------
df_cost_raw = None
if cost_file:
    df_cost_raw = load_csv(cost_file)
    if df_cost_raw is not None:
        df_cost_raw.columns = df_cost_raw.columns.map(str.strip)

# -------------- æ—¢å­˜ãƒ­ã‚¸ãƒƒã‚¯ã§ daily ã‚’ä½œæˆ (å£²ä¸Šãƒ»è²»ç”¨ãƒ»äººä»¶è²») --------------
# å£²ä¸Šãƒ»è²»ç”¨æ•´å½¢
df_sales = df_src[df_src.get("è²¸æ–¹å‹˜å®šç§‘ç›®") == "å£²ä¸Šé«˜"].copy()
df_sales_out = pd.DataFrame({
    "å–å¼•ã‚³ãƒ¼ãƒ‰": df_sales["è²¸æ–¹éƒ¨é–€"].astype(str).str.strip(),
    "å–å¼•å…ˆ": df_sales["è²¸æ–¹å–å¼•å…ˆå"],
    "å‹˜å®šç§‘ç›®": "å£²ä¸Šé«˜",
    "é‡‘é¡": pd.to_numeric(df_sales["è²¸æ–¹é‡‘é¡"], errors="coerce").fillna(0),
    "æ—¥ä»˜": df_sales["å–å¼•æ—¥"]
})

targets = ["å¤–æ³¨è²»","äº¤éš›è²»","æ—…è²»äº¤é€šè²»"]
df_exp = df_src[df_src.get("å€Ÿæ–¹å‹˜å®šç§‘ç›®").isin(targets)].copy()
df_exp_out = pd.DataFrame({
    "å–å¼•ã‚³ãƒ¼ãƒ‰": df_exp["å€Ÿæ–¹éƒ¨é–€"].astype(str).str.strip(),
    "å–å¼•å…ˆ": df_exp["å€Ÿæ–¹å–å¼•å…ˆå"],
    "å‹˜å®šç§‘ç›®": df_exp["å€Ÿæ–¹å‹˜å®šç§‘ç›®"],
    "é‡‘é¡": pd.to_numeric(df_exp["å€Ÿæ–¹é‡‘é¡"], errors="coerce").fillna(0),
    "æ—¥ä»˜": df_exp["å–å¼•æ—¥"]
})
combo = pd.concat([df_sales_out, df_exp_out], ignore_index=True)

# pivot
daily = (combo.pivot_table(index="å–å¼•ã‚³ãƒ¼ãƒ‰", columns="å‹˜å®šç§‘ç›®",
                           values="é‡‘é¡", aggfunc="sum",
                           fill_value=0)
         .reset_index())
meta = (combo.groupby("å–å¼•ã‚³ãƒ¼ãƒ‰")
             .agg({"æ—¥ä»˜":["min","max"],"å–å¼•å…ˆ":"first"}).reset_index())
meta.columns = ["å–å¼•ã‚³ãƒ¼ãƒ‰","æ—¥ä»˜ï¼ˆæœ€å°ï¼‰","æ—¥ä»˜ï¼ˆæœ€å¤§ï¼‰","å–å¼•å…ˆ"]
daily = daily.merge(meta, on="å–å¼•ã‚³ãƒ¼ãƒ‰", how="left")
if "å£²ä¸Šé«˜" not in daily.columns:
    daily["å£²ä¸Šé«˜"] = 0

# äººä»¶è²» (ç¨¼åƒã‚³ã‚¹ãƒˆ CSV) ------------------------------------------------------
if df_cost_raw is not None:
    id_c   = detect_col(df_cost_raw.columns, ["å–å¼•id","ãƒ¬ã‚³ãƒ¼ãƒ‰id","recordid"])
    cost_c = detect_col(df_cost_raw.columns, ["ç¨¼åƒã‚³ã‚¹ãƒˆ","äººä»¶è²»","cost"])
    name_c = detect_col(df_cost_raw.columns, ["ä¼šç¤¾å","å–å¼•å…ˆ","client","customer"])
    if id_c and cost_c:
        df_cost_raw[id_c] = df_cost_raw[id_c].map(normalize_id)
        df_cost = df_cost_raw.dropna(subset=[id_c]).copy()
        df_cost["äººä»¶è²»"] = pd.to_numeric(df_cost[cost_c], errors="coerce").fillna(0)
        agg = {"äººä»¶è²»":"sum"}
        if name_c: agg[name_c] = "first"
        cost_info = (
            df_cost.groupby(id_c, as_index=False)
                   .agg(agg)
                   .rename(columns={
                        id_c:   "å–å¼•ã‚³ãƒ¼ãƒ‰",
                        cost_c: "äººä»¶è²»",
                        **({name_c: "ç¨¼åƒå–å¼•å…ˆ"} if name_c else {})
                   })
        )
        daily["å–å¼•ã‚³ãƒ¼ãƒ‰"] = daily["å–å¼•ã‚³ãƒ¼ãƒ‰"].map(normalize_id)
        daily = daily.merge(cost_info, on="å–å¼•ã‚³ãƒ¼ãƒ‰", how="left")
    else:
        daily["äººä»¶è²»"] = 0
else:
    daily["äººä»¶è²»"] = 0

# ãƒã‚¹ã‚¿è£œå®Œ -----------------------------------------------------------
if master_map is not None:
    daily = daily.merge(master_map, on="å–å¼•ã‚³ãƒ¼ãƒ‰", how="left")
    need_fix = daily["å£²ä¸Šé«˜"] == 0
    daily.loc[need_fix, "å£²ä¸Šé«˜"] = daily.loc[need_fix, "ãƒã‚¹ã‚¿ãƒ¼é‡‘é¡"]
    has_cost_name = daily["ç¨¼åƒå–å¼•å…ˆ"].notna()
    daily.loc[need_fix & has_cost_name, "å–å¼•å…ˆ"] = \
        daily.loc[need_fix & has_cost_name, "ç¨¼åƒå–å¼•å…ˆ"]

# æŒ‡æ¨™è¨ˆç®— -------------------------------------------------------------
for c in ["å£²ä¸Šé«˜","å¤–æ³¨è²»","äº¤éš›è²»","æ—…è²»äº¤é€šè²»","äººä»¶è²»"]:
    daily[c] = pd.to_numeric(daily[c], errors="coerce").fillna(0)
daily["æœˆæ•°"] = daily.apply(
    lambda r: max((r["æ—¥ä»˜ï¼ˆæœ€å¤§ï¼‰"].year - r["æ—¥ä»˜ï¼ˆæœ€å°ï¼‰"].year)*12 +
                  (r["æ—¥ä»˜ï¼ˆæœ€å¤§ï¼‰"].month - r["æ—¥ä»˜ï¼ˆæœ€å°ï¼‰"].month) + 1, 1),
    axis=1)
daily["æœˆæ¬¡å£²ä¸Š"] = daily.apply(
    lambda r: r["å£²ä¸Šé«˜"]/r["æœˆæ•°"] if r["æœˆæ•°"] else 0, axis=1)
daily["ç²—åˆ©"] = (daily["å£²ä¸Šé«˜"] - daily["å¤–æ³¨è²»"] - daily["äº¤éš›è²»"]
                 - daily["æ—…è²»äº¤é€šè²»"] - daily["äººä»¶è²»"])
daily["ç²—åˆ©ç‡"] = daily.apply(
    lambda r: (r["ç²—åˆ©"]/r["å£²ä¸Šé«˜"]*100) if r["å£²ä¸Šé«˜"]>0 else 0, axis=1)
daily.rename(columns={"å–å¼•ã‚³ãƒ¼ãƒ‰":"ãƒ¬ã‚³ãƒ¼ãƒ‰ID"}, inplace=True)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ UI
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.sidebar.markdown("### ğŸ” ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼è¨­å®š")
id_val = st.sidebar.text_input("å–å¼•IDï¼ˆéƒ¨åˆ†ä¸€è‡´å¯ï¼‰", "")
min_date = df_src["å–å¼•æ—¥"].min().date()
max_date = df_src["å–å¼•æ—¥"].max().date()
start_date, end_date = st.sidebar.date_input("æœŸé–“ç¯„å›²", [min_date, max_date])

owner_sel = ind_sel = ind_det_sel = []
if "å–å¼•æ‹…å½“è€…" in daily.columns:
    owner_sel = st.sidebar.multiselect("å–å¼•æ‹…å½“è€…",
                                       sorted(daily["å–å¼•æ‹…å½“è€…"].dropna().unique()))
if "Industry" in daily.columns:
    ind_sel = st.sidebar.multiselect("Industry",
                                     sorted(daily["Industry"].dropna().unique()))
if "Industryè©³ç´°" in daily.columns:
    ind_det_sel = st.sidebar.multiselect("Industryè©³ç´°",
                                         sorted(daily["Industryè©³ç´°"].dropna().unique()))

mask  = daily["ãƒ¬ã‚³ãƒ¼ãƒ‰ID"].str.contains(id_val, na=False)
mask &= daily["æ—¥ä»˜ï¼ˆæœ€å¤§ï¼‰"].dt.date >= start_date
mask &= daily["æ—¥ä»˜ï¼ˆæœ€å°ï¼‰"].dt.date <= end_date
if owner_sel:
    mask &= daily["å–å¼•æ‹…å½“è€…"].isin(owner_sel)
if ind_sel:
    mask &= daily["Industry"].isin(ind_sel)
if ind_det_sel:
    mask &= daily["Industryè©³ç´°"].isin(ind_det_sel)
df_filtered = daily[mask].copy()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# æœˆæ¬¡ãƒ†ãƒ¼ãƒ–ãƒ« & æ¡ˆä»¶æ•°ï¼ˆæœŸé–“å†…ã®ã¿ï¼‰
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
records_sales, records_profit = [], []
for _, r in df_filtered.iterrows():
    for i in range(int(r["æœˆæ•°"])):
        dt_m = r["æ—¥ä»˜ï¼ˆæœ€å°ï¼‰"] + relativedelta(months=i)
        if not (start_date <= dt_m.date() <= end_date):
            continue
        ym = dt_m.strftime("%y/%m")
        records_sales.append({"å¹´æœˆè¡¨ç¤º":ym,"ãƒ¬ã‚³ãƒ¼ãƒ‰ID":r["ãƒ¬ã‚³ãƒ¼ãƒ‰ID"],
                              "å–å¼•å…ˆ":r["å–å¼•å…ˆ"],
                              "æœˆæ¬¡å£²ä¸Š":round(r["æœˆæ¬¡å£²ä¸Š"])})
        records_profit.append({"å¹´æœˆè¡¨ç¤º":ym,"ãƒ¬ã‚³ãƒ¼ãƒ‰ID":r["ãƒ¬ã‚³ãƒ¼ãƒ‰ID"],
                               "å–å¼•å…ˆ":r["å–å¼•å…ˆ"],
                               "æœˆæ¬¡ç²—åˆ©":round(r["ç²—åˆ©"]/r["æœˆæ•°"]) if r["æœˆæ•°"] else 0})
df_ms = pd.DataFrame(records_sales)
df_mp = pd.DataFrame(records_profit)

df_sales_p  = (df_ms.pivot_table(index=["ãƒ¬ã‚³ãƒ¼ãƒ‰ID","å–å¼•å…ˆ"],
                                 columns="å¹´æœˆè¡¨ç¤º",
                                 values="æœˆæ¬¡å£²ä¸Š", fill_value=0).reset_index())
df_profit_p = (df_mp.pivot_table(index=["ãƒ¬ã‚³ãƒ¼ãƒ‰ID","å–å¼•å…ˆ"],
                                 columns="å¹´æœˆè¡¨ç¤º",
                                 values="æœˆæ¬¡ç²—åˆ©", fill_value=0).reset_index())
time_cols = sorted(df_ms["å¹´æœˆè¡¨ç¤º"].unique().tolist())

for df_num in (df_sales_p, df_profit_p):
    for col in time_cols:
        df_num[col] = (df_num[col]
                       .astype(str)            # å¿µã®ãŸã‚ str ã«çµ±ä¸€
                       .str.replace(",", "")   # ã‚«ãƒ³ãƒé™¤å»
                       .astype(float)          # æ•°å€¤åŒ–
                       .fillna(0))

summary_sales = pd.DataFrame({
    "ãƒ¬ã‚³ãƒ¼ãƒ‰ID":["",""], "å–å¼•å…ˆ":["â‘ æœˆæ¬¡å£²ä¸Šåˆè¨ˆ","â‘¡å¹³å‡å£²ä¸Šå˜ä¾¡"],
    **{c:[df_sales_p[c].sum(), df_sales_p[c].mean()] for c in time_cols}
})
summary_profit = pd.DataFrame({
    "ãƒ¬ã‚³ãƒ¼ãƒ‰ID":["",""], "å–å¼•å…ˆ":["â‘¢æœˆæ¬¡ç²—åˆ©åˆè¨ˆ","â‘£å¹³å‡ç²—åˆ©å˜ä¾¡"],
    **{c:[df_profit_p[c].sum(), df_profit_p[c].mean()] for c in time_cols}
})
for c in time_cols:
    summary_sales[c]  = summary_sales[c].map(lambda x:f"{int(x):,}")
    summary_profit[c] = summary_profit[c].map(lambda x:f"{int(x):,}")

count_series = (df_ms[df_ms["æœˆæ¬¡å£²ä¸Š"]>0]
                .groupby("å¹´æœˆè¡¨ç¤º")["ãƒ¬ã‚³ãƒ¼ãƒ‰ID"].nunique()
                .reindex(time_cols, fill_value=0))

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Utilization è¨ˆç®—
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
util_hours_pivot = pd.DataFrame()
util_pct_pivot   = pd.DataFrame()
std_hours_row    = {}

if df_cost_raw is not None:
    # å¯¾è±¡åˆ—
    cons_c  = detect_col(df_cost_raw.columns, ["ã‚³ãƒ³ã‚µãƒ«ã‚¿ãƒ³ãƒˆå","æ°å","name"])
    hours_c = detect_col(df_cost_raw.columns, ["ç¨¼åƒæ™‚é–“","hours","workinghours","h"])
    date_c  = detect_col(df_cost_raw.columns, ["ç¨¼åƒæœˆ-æœˆæ¬¡","ç¨¼åƒæœˆ - æœˆæ¬¡","ç¨¼åƒæ—¥","date"])

    if cons_c and hours_c and date_c:
        dc = df_cost_raw[[cons_c, hours_c, date_c]].copy()

        # ç¨¼åƒæ™‚é–“ã‚’æ•°å€¤åŒ–
        dc[hours_c] = (dc[hours_c].astype(str)
                                   .str.replace(r"[^\d\.]", "", regex=True)
                                   .replace("", "0")
                                   .astype(float))

        dc[date_c] = pd.to_datetime(dc[date_c], errors="coerce")
        dc = dc.dropna(subset=[date_c]) 
        dc["å¹´æœˆè¡¨ç¤º"] = dc[date_c].dt.strftime("%y/%m")

        # ---------- æœŸé–“ãƒ•ã‚£ãƒ«ã‚¿ï¼š24/01 ä»¥é™ ----------
        util_time_cols = [c for c in sorted(dc["å¹´æœˆè¡¨ç¤º"].unique())
                          if c >= "24/01"]
        dc = dc[dc["å¹´æœˆè¡¨ç¤º"].isin(util_time_cols)]

        # æœˆæ¬¡ç¨¼åƒæ™‚é–“
        util_hours = (dc.pivot_table(index=cons_c, columns="å¹´æœˆè¡¨ç¤º",
                                     values=hours_c, aggfunc="sum",
                                     fill_value=0)
                      .reindex(columns=util_time_cols, fill_value=0))
        util_hours_pivot = util_hours.reset_index()

        # æ¨™æº–ç¨¼åƒæ™‚é–“
        for col in util_time_cols:
            y, m = 2000 + int(col[:2]), int(col[3:])
            _, last = calendar.monthrange(y, m)
            workdays = pd.date_range(f"{y}-{m:02d}-01",
                                     f"{y}-{m:02d}-{last}", freq="B").size
            std_hours_row[col] = workdays * 8

        # ãƒãƒ£ãƒ¼ã‚¸ãƒ£ãƒ“ãƒªãƒ†ã‚£ %
        util_pct = util_hours.copy()
        for col in util_time_cols:
            util_pct[col] = util_pct[col] / std_hours_row[col]
        util_pct_pivot = util_pct.reset_index()
    else:
        st.sidebar.warning("ç¨¼åƒã‚³ã‚¹ãƒˆã« ã‚³ãƒ³ã‚µãƒ«å / ç¨¼åƒæ™‚é–“ / æ—¥ä»˜ åˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ç”»é¢è¡¨ç¤º
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
tab1, tab2, tab3 = st.tabs(["ğŸ“Š Chart view","ğŸ“‹ Table view","ğŸ“ˆ Utilization"])

# ----- Chart view ------------------------------------------------------------
with tab1:
    st.subheader("æœˆæ¬¡åˆè¨ˆå£²ä¸Šãƒ»ç²—åˆ©")
    st.line_chart(pd.DataFrame({
        "æœˆæ¬¡å£²ä¸Šåˆè¨ˆ":[int(summary_sales.loc[0,c].replace(',','')) for c in time_cols],
        "æœˆæ¬¡ç²—åˆ©åˆè¨ˆ":[int(summary_profit.loc[0,c].replace(',','')) for c in time_cols]
    }, index=time_cols))
    st.subheader("æœˆæ¬¡å¹³å‡å£²ä¸Šãƒ»ç²—åˆ©")
    st.line_chart(pd.DataFrame({
        "å¹³å‡å£²ä¸Šå˜ä¾¡":[int(summary_sales.loc[1,c].replace(',','')) for c in time_cols],
        "å¹³å‡ç²—åˆ©å˜ä¾¡":[int(summary_profit.loc[1,c].replace(',','')) for c in time_cols]
    }, index=time_cols))
    st.subheader("æ¡ˆä»¶æ•°")
    st.bar_chart(pd.DataFrame({"æ¡ˆä»¶æ•°":count_series}, index=time_cols))

# ----- Table view ------------------------------------------------------------
with tab2:
    st.subheader("ğŸ“„ ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆåç›Šä¸€è¦§")
    # è¡¨ç¤ºåˆ—ã‚’æ‹¡å¼µï¼šãƒ¬ã‚³ãƒ¼ãƒ‰IDã®å¾Œã«æ—¥ä»˜æœ€å°ãƒ»æœ€å¤§ï¼ˆYY/MMï¼‰ã‚’æŒ¿å…¥
    show_cols = [
        "ãƒ¬ã‚³ãƒ¼ãƒ‰ID","æ—¥ä»˜ï¼ˆæœ€å°ï¼‰","æ—¥ä»˜ï¼ˆæœ€å¤§ï¼‰","å–å¼•å…ˆ","å–å¼•å","å–å¼•æ‹…å½“è€…",
        "Industry","Industryè©³ç´°","ææ¡ˆå•†æ",
        "å£²ä¸Šé«˜","äººä»¶è²»","å¤–æ³¨è²»","äº¤éš›è²»","æ—…è²»äº¤é€šè²»",
        "ç²—åˆ©","ç²—åˆ©ç‡"
    ]
    df_disp = df_filtered[show_cols].copy()
    # æ—¥ä»˜æœ€å°ãƒ»æœ€å¤§ã‚’YY/MMå½¢å¼ã§è¡¨ç¤º
    for c in ["æ—¥ä»˜ï¼ˆæœ€å°ï¼‰","æ—¥ä»˜ï¼ˆæœ€å¤§ï¼‰"]:
        df_disp[c] = pd.to_datetime(df_disp[c], errors="coerce").dt.strftime("%y/%m")
    # æ•°å€¤ã‚’ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã§ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
    num_cols = ["å£²ä¸Šé«˜","äººä»¶è²»","å¤–æ³¨è²»","äº¤éš›è²»","æ—…è²»äº¤é€šè²»","ç²—åˆ©"]
    for c in num_cols:
        df_disp[c] = df_disp[c].map(lambda x: f"{int(x):,}")
    # ç²—åˆ©ç‡ã‚’ãƒ‘ãƒ¼ã‚»ãƒ³ãƒˆè¡¨ç¤º
    df_disp["ç²—åˆ©ç‡"] = df_disp["ç²—åˆ©ç‡"].map(lambda x: f"{x:.1f}%")

    st.dataframe(df_disp, use_container_width=True)
    st.download_button(
        "ğŸ’¾ ç²—åˆ©é›†è¨ˆCSV",
        data=df_filtered.to_csv(index=False, encoding="utf-8-sig"),
        file_name="ç²—åˆ©é›†è¨ˆ.csv"
    )

    # æœˆæ¬¡å£²ä¸Š
    st.subheader("ğŸ“‹ æœˆæ¬¡å£²ä¸Š")
    def _format(df):
        for c in time_cols:
            df[c] = df[c].map(lambda x: f"{int(x):,}")
        return df
    st.dataframe(_format(df_sales_p.copy()), use_container_width=True)
    st.download_button("ğŸ’¾ æœˆæ¬¡å£²ä¸Šä¸€è¦§CSV",
        data=df_sales_p.to_csv(index=False, encoding="cp932"),
        file_name="æœˆæ¬¡å£²ä¸Šä¸€è¦§.csv")

    # æœˆæ¬¡ç²—åˆ©
    st.subheader("ğŸ“‹ æœˆæ¬¡ç²—åˆ©")
    st.dataframe(_format(df_profit_p.copy()), use_container_width=True)
    st.download_button("ğŸ’¾ æœˆæ¬¡ç²—åˆ©ä¸€è¦§CSV",
                       data=df_profit_p.to_csv(index=False, encoding="cp932"),
                       file_name="æœˆæ¬¡ç²—åˆ©ä¸€è¦§.csv")    

# ----- Utilization view ------------------------------------------------------
# ----- Utilization view ------------------------------------------------------
with tab3:
    # â‘  æ¨™æº–ç¨¼åƒæ™‚é–“
    st.subheader("æ¨™æº–ç¨¼åƒæ™‚é–“ / æœˆ")
    if std_hours_row:
        with st.expander("æ¨™æº–ç¨¼åƒæ™‚é–“", expanded=False):
            st.caption("å¹³æ—¥æ—¥æ•° Ã— 8h")
            st.table(pd.DataFrame([std_hours_row], index=["æ¨™æº–ç¨¼åƒæ™‚é–“(h)"]))
    else:
        st.info("ç¨¼åƒã‚³ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã«ç¨¼åƒæ™‚é–“ãŒç„¡ã„ãŸã‚åˆ©ç”¨ç‡ã‚’è¨ˆç®—ã§ãã¾ã›ã‚“ã€‚")

    # â‘¡ æœˆæ¬¡ç¨¼åƒæ™‚é–“ã¨ãƒãƒ£ãƒ¼ã‚¸ãƒ£ãƒ“ãƒªãƒ†ã‚£
    if not util_hours_pivot.empty:
        st.subheader("æœˆæ¬¡ç¨¼åƒæ™‚é–“ (h)")
        st.dataframe(util_hours_pivot, use_container_width=True)

        st.subheader("æœˆæ¬¡ç¨¼åƒç‡(%)")
        pct_df = util_pct_pivot.copy()
        for c in util_time_cols:
            pct_df[c] = pct_df[c].map(lambda x: f"{x:.0%}")
        st.dataframe(pct_df, use_container_width=True)

        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ã“ã“ã‹ã‚‰è©³ç´°ã‚»ã‚¯ã‚·ãƒ§ãƒ³ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        st.markdown("---")
        st.subheader("ã‚³ãƒ³ã‚µãƒ«ã‚¿ãƒ³ãƒˆåˆ¥ç¨¼åƒç‡æ¨ç§»ã¨è©³ç´°ãƒ‡ãƒ¼ã‚¿")

        # ãƒ—ãƒ«ãƒ€ã‚¦ãƒ³ã§ã‚³ãƒ³ã‚µãƒ«é¸æŠ
        cons_col = util_hours_pivot.columns[0]
        names    = sorted(util_hours_pivot[cons_col].unique())
        sel      = st.selectbox("ã‚³ãƒ³ã‚µãƒ«ã‚¿ãƒ³ãƒˆã‚’é¸æŠ", names)

        # æŠ˜ã‚Œç·šã‚°ãƒ©ãƒ•ï¼šé¸æŠè€…ã®ãƒãƒ£ãƒ¼ã‚¸ãƒ£ãƒ“ãƒªãƒ†ã‚£
        sel_pct = util_pct_pivot.set_index(cons_col).loc[sel, util_time_cols]
        df_chart = pd.DataFrame({"ç¨¼åƒç‡": sel_pct.values}, index=util_time_cols)
        import altair as alt
        chart = (
            alt.Chart(df_chart.reset_index().melt("index"))
               .mark_line(point=True)
               .encode(
                   x=alt.X("index:N", title="å¹´æœˆ"),
                   y=alt.Y("value:Q", axis=alt.Axis(format=".0%", title="ç¨¼åƒç‡")),
                   color=alt.value("#1f77b4")
               )
               .properties(height=300)
        )
        st.altair_chart(chart, use_container_width=True)

        # è©³ç´°ãƒ†ãƒ¼ãƒ–ãƒ«ï¼šè©²å½“ã‚³ãƒ³ã‚µãƒ«Ã—å…¨æœˆ
        df_detail = df_cost_raw.copy()
        df_detail[date_c] = pd.to_datetime(df_detail[date_c], errors="coerce")
        df_detail["ç¨¼åƒæœˆ-æœˆæ¬¡"] = df_detail[date_c].dt.strftime("%y/%m")

        assign_c = detect_col(df_detail.columns,
                              ["ã‚¢ã‚µã‚¤ãƒ³å±¥æ­´å","assignhistory","history"])

        df_det = df_detail[
            (df_detail[cons_col] == sel) &
            (df_detail["ç¨¼åƒæœˆ-æœˆæ¬¡"].isin(util_time_cols))
        ].copy()

        # æ•°å€¤åŒ– & ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
        df_det[hours_c] = pd.to_numeric(df_det[hours_c], errors="coerce").fillna(0)
        df_det[cost_c]  = pd.to_numeric(df_det[cost_c], errors="coerce").fillna(0)
        df_det["ç¨¼åƒæ™‚é–“"]   = df_det[hours_c].map(lambda x: f"{x:,}")
        df_det["ç¨¼åƒã‚³ã‚¹ãƒˆ"] = df_det[cost_c].map(lambda x: f"{int(x):,}")

        # åˆ—é †ãƒ»ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’æ—¥æœ¬èªåŒ–
        df_det = df_det[["ç¨¼åƒæœˆ-æœˆæ¬¡", id_c, name_c, assign_c, "ç¨¼åƒæ™‚é–“", "ç¨¼åƒã‚³ã‚¹ãƒˆ"]]
        df_det.columns = ["ç¨¼åƒæœˆ-æœˆæ¬¡","å–å¼•ID","ä¼šç¤¾å","ã‚¢ã‚µã‚¤ãƒ³å±¥æ­´å","ç¨¼åƒæ™‚é–“","ç¨¼åƒã‚³ã‚¹ãƒˆ"]

        st.dataframe(df_det, use_container_width=True)
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ è©³ç´°ã‚»ã‚¯ã‚·ãƒ§ãƒ³ ã“ã“ã¾ã§ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    else:
        st.info("åˆ©ç”¨ç‡ã‚’è¨ˆç®—ã§ãã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
