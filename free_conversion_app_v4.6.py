import streamlit as st
import pandas as pd
import zipfile, io, re, tempfile, gdown, os
from datetime import date
from dateutil.relativedelta import relativedelta

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ãƒšãƒ¼ã‚¸è¨­å®š
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(page_title="ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆåç›Š v7.0", layout="wide")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def detect_col(cols, patterns):
    for p in patterns:
        hits = [c for c in cols if re.sub(r"\s+", "", str(c)).casefold() == p]
        if hits:
            return hits[0]
    return None


def normalize_id(x):
    if pd.isna(x):
        return None
    s = str(x).strip()
    return None if s == "" or s.lower() in {"nan", "none"} else s


# â”€â”€ CSV / ZIP ãƒ­ãƒ¼ãƒ€ ---------------------------------------------------------
def load_csv(uploaded):
    """(1) å˜ä½“ CSV  (2) ZIP å†… CSV ã‚’ DataFrame ã§è¿”ã™"""
    if uploaded is None:
        return None

    # ZIP ã‹åˆ¤å®š
    if uploaded.name.lower().endswith(".zip"):
        try:
            with zipfile.ZipFile(uploaded) as zf:
                csv_list = [n for n in zf.namelist()
                            if n.lower().endswith(".csv") and not n.endswith("/")]
                if not csv_list:
                    st.error("ZIP ã« CSV ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
                    return None
                target = csv_list[0] if len(csv_list) == 1 else \
                         st.selectbox("ZIP å†… CSV ã‚’é¸æŠã—ã¦ãã ã•ã„", csv_list)
                with zf.open(target) as fp:
                    for enc in ("utf-8-sig", "cp932", "utf-8"):
                        try:
                            txt = fp.read().decode(enc)
                            return pd.read_csv(io.StringIO(txt))
                        except Exception:
                            fp.seek(0)
        except zipfile.BadZipFile:
            st.error("ZIP ãƒ•ã‚¡ã‚¤ãƒ«ãŒå£Šã‚Œã¦ã„ã¾ã™ã€‚")
            return None

    # é€šå¸¸ã® CSV
    for enc in ("utf-8-sig", "cp932", "utf-8"):
        try:
            txt = uploaded.read().decode(enc)
            return pd.read_csv(io.StringIO(txt))
        except Exception:
            uploaded.seek(0)

    st.error("CSV ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚æ–‡å­—ã‚³ãƒ¼ãƒ‰ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
    return None


# â”€â”€ Google Drive å…±æœ‰ãƒªãƒ³ã‚¯ã‹ã‚‰ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ ---------------------------------
def read_gdrive_csv_gdown(share_url: str, **kwargs) -> pd.DataFrame:
    """Google Drive ã®å…±æœ‰ãƒªãƒ³ã‚¯ã‚’ gdown ã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã— DataFrame ã‚’è¿”ã™"""
    with tempfile.NamedTemporaryFile(delete=False, suffix=".csv") as tmp:
        gdown.download(url=share_url, output=tmp.name, quiet=False, fuzzy=True)
        return pd.read_csv(tmp.name, **kwargs)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ä»•è¨³å¸³ãƒ‡ãƒ¼ã‚¿å–å¾— UIï¼ˆCSV / ZIP / Google Driveï¼‰
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
with st.sidebar.expander("ğŸ“‚ ä»•è¨³å¸³ãƒ‡ãƒ¼ã‚¿ã®å–å¾—", expanded=True):
    tab_local, tab_drive = st.tabs(["ãƒ­ãƒ¼ã‚«ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", "Google Drive"])

    with tab_local:
        uploaded_file = st.file_uploader("CSV ã¾ãŸã¯ ZIP ã‚’é¸æŠ", type=["csv", "zip"])
        

    with tab_drive:
        gdrive_url = st.text_input(
            "Drive å…±æœ‰ãƒªãƒ³ã‚¯ã‚’è²¼ã£ã¦ Enter",
            placeholder="https://drive.google.com/file/d/â€¦/view?usp=sharing"
        )
        if gdrive_url and not gdrive_url.startswith("http"):
            st.warning("ãƒªãƒ³ã‚¯å½¢å¼ãŒæ­£ã—ãã‚ã‚Šã¾ã›ã‚“ã€‚")
            gdrive_url = ""

    master_file = st.sidebar.file_uploader("å–å¼•ãƒã‚¹ã‚¿", type="csv")
    cost_file   = st.sidebar.file_uploader("ç¨¼åƒã‚³ã‚¹ãƒˆ", type="csv")


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ä»•è¨³å¸³èª­è¾¼
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
df_src = None
if uploaded_file is not None:
    df_src = load_csv(uploaded_file)
elif gdrive_url:
    try:
        df_src = read_gdrive_csv_gdown(gdrive_url, encoding="cp932")
    except Exception as e:
        st.error(f"Google Drive èª­ã¿è¾¼ã¿å¤±æ•—: {e}")

if df_src is None:
    st.stop()

st.success(f"ä»•è¨³å¸³ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ ({len(df_src):,} è¡Œ)")
df_src["å–å¼•æ—¥"] = pd.to_datetime(df_src["å–å¼•æ—¥"], errors="coerce")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# å–å¼•ãƒã‚¹ã‚¿èª­è¾¼
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
master_map = None
if master_file:
    df_master = load_csv(master_file)
    if df_master is not None:
        df_master.columns = df_master.columns.map(str.strip)

        id_col   = detect_col(df_master.columns, ["å–å¼•id","ãƒ¬ã‚³ãƒ¼ãƒ‰id","recordid","dealid"])
        name_col = detect_col(df_master.columns, ["å–å¼•å…ˆ","ä¼šç¤¾å","customer","client"])
        amt_col  = detect_col(df_master.columns, ["é‡‘é¡","å£²ä¸Šé‡‘é¡","è¦‹ç©é‡‘é¡","amount"])
        title_col = detect_col(df_master.columns, ["å–å¼•å","æ¡ˆä»¶å","dealname","title"])
        owner_col = detect_col(df_master.columns, ["å–å¼•æ‹…å½“è€…","æ‹…å½“è€…","owner","sales"])
        ind_col   = detect_col(df_master.columns, ["industry","æ¥­ç•Œ"])
        ind_det_col = detect_col(df_master.columns, ["industryè©³ç´°","industrydetail","æ¥­ç•Œè©³ç´°"])

        if id_col and amt_col:
            df_master[id_col]  = df_master[id_col].map(normalize_id)
            df_master[amt_col] = pd.to_numeric(df_master[amt_col], errors="coerce").fillna(0)

            keep = {id_col: "å–å¼•ã‚³ãƒ¼ãƒ‰", amt_col: "ãƒã‚¹ã‚¿ãƒ¼é‡‘é¡"}
            if name_col:   keep[name_col]   = "ãƒã‚¹ã‚¿ãƒ¼å–å¼•å…ˆ"
            if title_col:  keep[title_col]  = "å–å¼•å"
            if owner_col:  keep[owner_col]  = "å–å¼•æ‹…å½“è€…"
            if ind_col:    keep[ind_col]    = "Industry"
            if ind_det_col:keep[ind_det_col]= "Industryè©³ç´°"

            master_map = (df_master[list(keep)]
                          .dropna(subset=[id_col])
                          .rename(columns=keep)
                          .drop_duplicates(subset=["å–å¼•ã‚³ãƒ¼ãƒ‰"]))
        else:
            st.sidebar.warning("âš ï¸ ãƒã‚¹ã‚¿: ID ã¾ãŸã¯ é‡‘é¡ åˆ—ãŒä¸è¶³")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ä»•è¨³ãƒ‡ãƒ¼ã‚¿æ•´å½¢ï¼ˆå£²ä¸Šãƒ»è²»ç”¨ï¼‰
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
df_sales = df_src[df_src.get("è²¸æ–¹å‹˜å®šç§‘ç›®") == "å£²ä¸Šé«˜"].copy()
df_sales_out = pd.DataFrame({
    "å–å¼•ã‚³ãƒ¼ãƒ‰": df_sales["è²¸æ–¹éƒ¨é–€"].astype(str).str.strip(),
    "å–å¼•å…ˆ"    : df_sales["è²¸æ–¹å–å¼•å…ˆå"],
    "å‹˜å®šç§‘ç›®"  : "å£²ä¸Šé«˜",
    "é‡‘é¡"      : pd.to_numeric(df_sales["è²¸æ–¹é‡‘é¡"], errors="coerce").fillna(0),
    "æ—¥ä»˜"      : df_sales["å–å¼•æ—¥"]
})

targets = ["å¤–æ³¨è²»", "äº¤éš›è²»", "æ—…è²»äº¤é€šè²»"]
df_exp = df_src[df_src.get("å€Ÿæ–¹å‹˜å®šç§‘ç›®").isin(targets)].copy()
df_exp_out = pd.DataFrame({
    "å–å¼•ã‚³ãƒ¼ãƒ‰": df_exp["å€Ÿæ–¹éƒ¨é–€"].astype(str).str.strip(),
    "å–å¼•å…ˆ"    : df_exp["å€Ÿæ–¹å–å¼•å…ˆå"],
    "å‹˜å®šç§‘ç›®"  : df_exp["å€Ÿæ–¹å‹˜å®šç§‘ç›®"],
    "é‡‘é¡"      : pd.to_numeric(df_exp["å€Ÿæ–¹é‡‘é¡"], errors="coerce").fillna(0),
    "æ—¥ä»˜"      : df_exp["å–å¼•æ—¥"]
})

combo = pd.concat([df_sales_out, df_exp_out], ignore_index=True)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# pivot â†’ daily
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
daily = (combo.pivot_table(index="å–å¼•ã‚³ãƒ¼ãƒ‰",
                           columns="å‹˜å®šç§‘ç›®",
                           values="é‡‘é¡",
                           aggfunc="sum",
                           fill_value=0)
         .reset_index())

meta = (combo.groupby("å–å¼•ã‚³ãƒ¼ãƒ‰")
             .agg({"æ—¥ä»˜": ["min","max"], "å–å¼•å…ˆ":"first"})
             .reset_index())
meta.columns = ["å–å¼•ã‚³ãƒ¼ãƒ‰","æ—¥ä»˜ï¼ˆæœ€å°ï¼‰","æ—¥ä»˜ï¼ˆæœ€å¤§ï¼‰","å–å¼•å…ˆ"]
daily = daily.merge(meta, on="å–å¼•ã‚³ãƒ¼ãƒ‰", how="left")
if "å£²ä¸Šé«˜" not in daily.columns:
    daily["å£²ä¸Šé«˜"] = 0

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ç¨¼åƒã‚³ã‚¹ãƒˆçµ±åˆ
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if cost_file:
    df_cost = load_csv(cost_file)
    if df_cost is not None:
        df_cost.columns = df_cost.columns.map(str.strip)
        id_c   = detect_col(df_cost.columns, ["å–å¼•id","ãƒ¬ã‚³ãƒ¼ãƒ‰id","recordid"])
        cost_c = detect_col(df_cost.columns, ["ç¨¼åƒã‚³ã‚¹ãƒˆ","äººä»¶è²»","cost"])
        name_c = detect_col(df_cost.columns, ["ä¼šç¤¾å","å–å¼•å…ˆ","client","customer"])
        if id_c and cost_c:
            df_cost[id_c] = df_cost[id_c].map(normalize_id)
            df_cost = df_cost.dropna(subset=[id_c])
            df_cost["äººä»¶è²»"] = pd.to_numeric(df_cost[cost_c], errors="coerce").fillna(0)

            agg = {"äººä»¶è²»": "sum"}
            if name_c:
                agg[name_c] = "first"
            cost_info = (df_cost.groupby(id_c, as_index=False)
                         .agg(agg)
                         .rename(columns={id_c:"å–å¼•ã‚³ãƒ¼ãƒ‰"}))
            if name_c:
                cost_info = cost_info.rename(columns={name_c:"ç¨¼åƒå–å¼•å…ˆ"})
            daily["å–å¼•ã‚³ãƒ¼ãƒ‰"] = daily["å–å¼•ã‚³ãƒ¼ãƒ‰"].map(normalize_id)
            daily = daily.merge(cost_info, on="å–å¼•ã‚³ãƒ¼ãƒ‰", how="left")
        else:
            daily["äººä»¶è²»"] = 0
    else:
        daily["äººä»¶è²»"] = 0
else:
    daily["äººä»¶è²»"] = 0

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ãƒã‚¹ã‚¿è£œå®Œï¼ˆå£²ä¸Šã®ã¿ã€å–å¼•å…ˆã¯ç¨¼åƒCSVå„ªå…ˆï¼‰
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if master_map is not None:
    daily = daily.merge(master_map, on="å–å¼•ã‚³ãƒ¼ãƒ‰", how="left")
    need_fix = daily["å£²ä¸Šé«˜"] == 0
    daily.loc[need_fix, "å£²ä¸Šé«˜"] = daily.loc[need_fix, "ãƒã‚¹ã‚¿ãƒ¼é‡‘é¡"]
    has_cost_name = daily["ç¨¼åƒå–å¼•å…ˆ"].notna()
    daily.loc[need_fix & has_cost_name, "å–å¼•å…ˆ"] = \
        daily.loc[need_fix & has_cost_name, "ç¨¼åƒå–å¼•å…ˆ"]

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# æŒ‡æ¨™è¨ˆç®—
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
num_cols = daily.select_dtypes(include="number").columns
daily[num_cols] = daily[num_cols].fillna(0)
for c in ["å£²ä¸Šé«˜","å¤–æ³¨è²»","äº¤éš›è²»","æ—…è²»äº¤é€šè²»","äººä»¶è²»"]:
    daily[c] = pd.to_numeric(daily[c], errors="coerce").fillna(0)

daily["æœˆæ•°"] = daily.apply(
    lambda r: max((r["æ—¥ä»˜ï¼ˆæœ€å¤§ï¼‰"].year - r["æ—¥ä»˜ï¼ˆæœ€å°ï¼‰"].year)*12 +
                  (r["æ—¥ä»˜ï¼ˆæœ€å¤§ï¼‰"].month - r["æ—¥ä»˜ï¼ˆæœ€å°ï¼‰"].month) + 1, 1),
    axis=1)
daily["æœˆæ¬¡å£²ä¸Š"] = daily.apply(
    lambda r: r["å£²ä¸Šé«˜"]/r["æœˆæ•°"] if r["æœˆæ•°"]>0 else 0,
    axis=1)
daily["ç²—åˆ©"] = (daily["å£²ä¸Šé«˜"] - daily["å¤–æ³¨è²»"]
                 - daily["äº¤éš›è²»"] - daily["æ—…è²»äº¤é€šè²»"] - daily["äººä»¶è²»"])
daily["ç²—åˆ©ç‡"] = daily.apply(
    lambda r: (r["ç²—åˆ©"]/r["å£²ä¸Šé«˜"]*100) if r["å£²ä¸Šé«˜"]>0 else 0,
    axis=1)

daily.rename(columns={"å–å¼•ã‚³ãƒ¼ãƒ‰":"ãƒ¬ã‚³ãƒ¼ãƒ‰ID"}, inplace=True)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ UI
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.sidebar.markdown("### ğŸ” ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼è¨­å®š")
id_val = st.sidebar.text_input("å–å¼•IDï¼ˆéƒ¨åˆ†ä¸€è‡´å¯ï¼‰", "")

min_date = df_src["å–å¼•æ—¥"].min().date()
max_date = df_src["å–å¼•æ—¥"].max().date()
start_date, end_date = st.sidebar.date_input("æœŸé–“ç¯„å›²", [min_date, max_date])

owner_sel, ind_sel, ind_det_sel = [], [], []
if "å–å¼•æ‹…å½“è€…" in daily.columns:
    owner_sel = st.sidebar.multiselect("å–å¼•æ‹…å½“è€…",
                                       sorted(daily["å–å¼•æ‹…å½“è€…"].dropna().unique()))
if "Industry" in daily.columns:
    ind_sel = st.sidebar.multiselect("Industry",
                                     sorted(daily["Industry"].dropna().unique()))
if "Industryè©³ç´°" in daily.columns:
    ind_det_sel = st.sidebar.multiselect("Industryè©³ç´°",
                                         sorted(daily["Industryè©³ç´°"].dropna().unique()))

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ãƒ¬ã‚³ãƒ¼ãƒ‰ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
mask  = daily["ãƒ¬ã‚³ãƒ¼ãƒ‰ID"].str.contains(id_val, na=False)
mask &= daily["æ—¥ä»˜ï¼ˆæœ€å¤§ï¼‰"].dt.date >= start_date
mask &= daily["æ—¥ä»˜ï¼ˆæœ€å°ï¼‰"].dt.date <= end_date
if owner_sel:
    mask &= daily["å–å¼•æ‹…å½“è€…"].isin(owner_sel)
if ind_sel:
    mask &= daily["Industry"].isin(ind_sel)
if ind_det_sel:
    mask &= daily["Industryè©³ç´°"].isin(ind_det_sel)

df_filtered = daily[mask].copy()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# æœˆæ¬¡ãƒ†ãƒ¼ãƒ–ãƒ« & æ¡ˆä»¶æ•°ç”Ÿæˆï¼ˆæœŸé–“å†…ã®æœˆã®ã¿ï¼‰
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
records_sales, records_profit = [], []
for _, r in df_filtered.iterrows():
    for i in range(int(r["æœˆæ•°"])):
        dt_month = r["æ—¥ä»˜ï¼ˆæœ€å°ï¼‰"] + relativedelta(months=i)
        if not (start_date <= dt_month.date() <= end_date):
            continue
        ym_disp = dt_month.strftime("%y/%m")
        records_sales.append({
            "å¹´æœˆè¡¨ç¤º": ym_disp, "ãƒ¬ã‚³ãƒ¼ãƒ‰ID": r["ãƒ¬ã‚³ãƒ¼ãƒ‰ID"],
            "å–å¼•å…ˆ": r["å–å¼•å…ˆ"], "æœˆæ¬¡å£²ä¸Š": round(r["æœˆæ¬¡å£²ä¸Š"])
        })
        records_profit.append({
            "å¹´æœˆè¡¨ç¤º": ym_disp, "ãƒ¬ã‚³ãƒ¼ãƒ‰ID": r["ãƒ¬ã‚³ãƒ¼ãƒ‰ID"],
            "å–å¼•å…ˆ": r["å–å¼•å…ˆ"],
            "æœˆæ¬¡ç²—åˆ©": round(r["ç²—åˆ©"]/r["æœˆæ•°"]) if r["æœˆæ•°"]>0 else 0
        })

df_ms = pd.DataFrame(records_sales)
df_mp = pd.DataFrame(records_profit)

df_sales_p = (df_ms.pivot_table(index=["ãƒ¬ã‚³ãƒ¼ãƒ‰ID","å–å¼•å…ˆ"],
                                columns="å¹´æœˆè¡¨ç¤º",
                                values="æœˆæ¬¡å£²ä¸Š",
                                aggfunc="sum", fill_value=0)
              .reset_index())
df_profit_p = (df_mp.pivot_table(index=["ãƒ¬ã‚³ãƒ¼ãƒ‰ID","å–å¼•å…ˆ"],
                                 columns="å¹´æœˆè¡¨ç¤º",
                                 values="æœˆæ¬¡ç²—åˆ©",
                                 aggfunc="sum", fill_value=0)
               .reset_index())

time_cols = sorted(df_ms["å¹´æœˆè¡¨ç¤º"].unique().tolist())

summary_sales = pd.DataFrame({
    "ãƒ¬ã‚³ãƒ¼ãƒ‰ID":["",""],
    "å–å¼•å…ˆ":["â‘ æœˆæ¬¡å£²ä¸Šåˆè¨ˆ","â‘¡å¹³å‡å£²ä¸Šå˜ä¾¡"],
    **{c:[df_sales_p[c].sum(), df_sales_p[c].mean()] for c in time_cols}
})
for c in time_cols:
    summary_sales[c] = summary_sales[c].map(lambda x: f"{int(x):,}")

summary_profit = pd.DataFrame({
    "ãƒ¬ã‚³ãƒ¼ãƒ‰ID":["",""],
    "å–å¼•å…ˆ":["â‘¢æœˆæ¬¡ç²—åˆ©åˆè¨ˆ","â‘£å¹³å‡ç²—åˆ©å˜ä¾¡"],
    **{c:[df_profit_p[c].sum(), df_profit_p[c].mean()] for c in time_cols}
})
for c in time_cols:
    summary_profit[c] = summary_profit[c].map(lambda x: f"{int(x):,}")

count_series = (df_ms[df_ms["æœˆæ¬¡å£²ä¸Š"]>0]
                .groupby("å¹´æœˆè¡¨ç¤º")["ãƒ¬ã‚³ãƒ¼ãƒ‰ID"]
                .nunique()
                .reindex(time_cols, fill_value=0))

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# è¡¨ç¤º
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
tab1, tab2 = st.tabs(["ğŸ“Š Chart view", "ğŸ“‹ Table view"])

with tab1:
    st.subheader("æœˆæ¬¡åˆè¨ˆå£²ä¸Šãƒ»ç²—åˆ©")
    st.line_chart(pd.DataFrame({
        "æœˆæ¬¡å£²ä¸Šåˆè¨ˆ":[int(summary_sales.loc[0,c].replace(',','')) for c in time_cols],
        "æœˆæ¬¡ç²—åˆ©åˆè¨ˆ":[int(summary_profit.loc[0,c].replace(',','')) for c in time_cols]
    }, index=time_cols))

    st.subheader("æœˆæ¬¡å¹³å‡å£²ä¸Šãƒ»ç²—åˆ©")
    st.line_chart(pd.DataFrame({
        "å¹³å‡å£²ä¸Šå˜ä¾¡":[int(summary_sales.loc[1,c].replace(',','')) for c in time_cols],
        "å¹³å‡ç²—åˆ©å˜ä¾¡":[int(summary_profit.loc[1,c].replace(',','')) for c in time_cols]
    }, index=time_cols))

    st.subheader("æ¡ˆä»¶æ•°")
    st.bar_chart(pd.DataFrame({"æ¡ˆä»¶æ•°":count_series}, index=time_cols))

with tab2:
    st.subheader("ğŸ“„ ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆåç›Šä¸€è¦§")
    st.dataframe(df_filtered[["ãƒ¬ã‚³ãƒ¼ãƒ‰ID","å–å¼•å…ˆ","å£²ä¸Šé«˜","ç²—åˆ©","ç²—åˆ©ç‡"]], use_container_width=True)
    st.download_button("ğŸ’¾ ç²—åˆ©é›†è¨ˆCSV",
        data=df_filtered.to_csv(index=False, encoding="utf-8-sig"),
        file_name="ç²—åˆ©é›†è¨ˆ.csv")

    st.subheader("ğŸ“‹ æœˆæ¬¡å£²ä¸Š")
    ms_disp = df_sales_p.copy()
    for c in time_cols:
        ms_disp[c] = ms_disp[c].map(lambda x: f"{int(x):,}")
    st.dataframe(ms_disp[["ãƒ¬ã‚³ãƒ¼ãƒ‰ID","å–å¼•å…ˆ"]+time_cols], use_container_width=True)
    st.download_button("ğŸ’¾ æœˆæ¬¡å£²ä¸Šä¸€è¦§CSV",
        data=df_sales_p.to_csv(index=False, encoding="cp932"),
        file_name="æœˆæ¬¡å£²ä¸Šä¸€è¦§.csv")

    st.subheader("ğŸ“‹ æœˆæ¬¡ç²—åˆ©")
    mp_disp = df_profit_p.copy()
    for c in time_cols:
        mp_disp[c] = mp_disp[c].map(lambda x: f"{int(x):,}")
    st.dataframe(mp_disp[["ãƒ¬ã‚³ãƒ¼ãƒ‰ID","å–å¼•å…ˆ"]+time_cols], use_container_width=True)
    st.download_button("ğŸ’¾ æœˆæ¬¡ç²—åˆ©ä¸€è¦§CSV",
        data=df_profit_p.to_csv(index=False, encoding="cp932"),
        file_name="æœˆæ¬¡ç²—åˆ©ä¸€è¦§.csv")
